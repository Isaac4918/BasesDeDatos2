#### Isaac Araya Solano | Carnet: 2018151703
#### Resumen #2

<h2 style="color:rgb(30, 60, 90);">Introducing Amazon Redshift</h2>

In the past, when the data managed by a company grew, they had to choose between accepting slow performance or investing time, effort and money on an upgrade process. They were forced to update hardware sometimes and it made troublesome to have healthy relationships with database providers. Then cloud data warehouses like Amazon Redshift appeared and changed how enterprises think about data warehousing since it lowered costs and effort. Amazon Redshift is a fast, fully managed, petabyte-scale data warehousing solution that makes it simple and cost-effective to analyze large volumes of data using existing business intelligence (BI) tools.

<h2 style="color:rgb(30, 60, 90);">Modern analytics and data warehousing architecture</h2>

Data typically flows into a data warehouse from transactional systems and other relational databases, and typically includes structured, semi-structured, and unstructured data. 

Differences between Data warehouses and OLTP databases:
- Data warehouses are optimized for batched write operations and reading high volumes of data.
- OLTP databases are optimized for continuous write operations and high volumes of small read operations.

To get the benefits of using a data warehouse managed as a separate data store with your source OLTP or other source system, we recommend that you build an efficient data pipeline. It must extract data from the source system and converts its schema to be suitable for the warehouse and then load it to the warehouse. 

<h3 style="color:rgb(90, 60, 30);">AWS analytics services</h3>

This help enterprises convert their data to answers by providing analytics services between gload data warehouses to serverless data lakes. AWS helps you make everything work together by giving you:

- Facilitating building data lakes and warehouse
- A secure cloud storage, compute and network infrastructure adapted to specific needs
- An analytics stack with a set of tools 
- The best performance, scalability and lowest cost. 

<h3 style="color:rgb(90, 60, 30);">Analytics architecture</h3>
Analytics pipelines are designed to handle large volumes of stream data from different sources. 

Analytics pipeline has these stages:
- Collect data
- Store the data
- Process the data
- Analyze and visualize the data

<h4 style="color:rgb(150, 90, 60);">Data collection</h4>
There are different types of data and AWS provides solutions for data storage for all of them. 

<h5 style="color:rgb(150, 90, 60);">Transactional Data</h5>
Usually stored in relational databases or NO SQL data bases.

Databases:
- Amazon DynamoDB(NO SQL)
- Amazon Aurora: compatible with MYSQL and PostgreSQL
- Amazon RDS

<h5 style="color:rgb(150, 90, 60);">Log data</h5>
Amazon S3 is a popular storage solution for non-transactional data, such as log data used for analytics.

<h5 style="color:rgb(150, 90, 60);">Streaming data</h5>
You can use Amazon MSK and Amazon Kisesis for this data.

<h5 style="color:rgb(150, 90, 60);">IoT data</h5>
For connected devices you can use AWS IoT to interact easily with AWS cloud to process this data without having to manage any infraestructure. 

<h4 style="color:rgb(150, 90, 60);">Data Processing</h4>

<h5 style="color:rgb(150, 90, 60);">Batch Processing</h5>

- Extract Transform Load (ETL): Is the process of pulling data from multiple sources to load into data warehousing systems. The data extracted is cleansed, enriched, transformed and loaded into a data warehouse. 
- Extract Load Transform (ELT):